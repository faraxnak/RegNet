name: "regnet"

layer {
  name: "data"
  type: "DenseRegisterData"
  top: "ref"
  top: "fl"
  top: "label"
  dense_image_data_param {
    source: "/home/bisipl/Documents/MATLAB/RegNet/trainAddress.txt" # Change this to the absolute path to your data file
    batch_size: 1         # Change this number to a batch size that will fit on your GPU
    shuffle: true
    is_color: false
  }
  include {
    phase: TEST
  }
}

# reference image
# encoder one
layer { bottom: "ref"                  top: "ref_d0b"   name: "ref_conv_d0a-b"     type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } convolution_param { num_output: 64 pad: 1 kernel_size: 3 weight_filler { type: "msra" } bias_filler { type: "constant" }} }
layer { bottom: "ref_d0b"              top: "ref_d0b"   name: "ref_relu_d0b"       type: "ReLU" }
layer { bottom: "ref_d0b"              top: "ref_d0c"   name: "ref_conv_d0b-c"     type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 64 pad: 1 kernel_size: 3 weight_filler { type: "msra"} bias_filler { type: "constant" }} }
layer { bottom: "ref_d0c"              top: "ref_d0c"   name: "ref_relu_d0c"       type: "ReLU" }
layer { bottom: "ref_d0c"              top: "ref_d0d"   name: "ref_conv_d0c-d"     type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 64 pad: 1 kernel_size: 3 weight_filler { type: "msra"} bias_filler { type: "constant" }} }
layer { bottom: "ref_d0d"              top: "ref_d0d"   name: "ref_relu_d0d"       type: "ReLU" }


# conv layer with stride two instead of pooling
layer { bottom: "ref_d0d"               top: "ref_d0pool"   name:"ref_d0pool"             type:"Convolution" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 64 pad: 1 kernel_size: 3 stride: 2 weight_filler { type: "msra" } bias_filler { type: "constant" } }}
layer { bottom: "ref_d0pool"            top: "ref_d0pool"   name: "ref_relu_d0pool"       type: "ReLU" }

## encoder two

layer { bottom: "ref_d0pool"           top: "ref_d1b"   name: "ref_conv_d1a-b"     type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 128 pad: 1 kernel_size: 3 weight_filler { type: "msra" } bias_filler { type: "constant" } } }
layer { bottom: "ref_d1b"              top: "ref_d1b"   name: "ref_relu_d1b"       type: "ReLU" }
layer { bottom: "ref_d1b"              top: "ref_d1c"   name: "ref_conv_d1b-c"     type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 128 pad: 1 kernel_size: 3 weight_filler { type: "msra" } bias_filler { type: "constant" } } }
layer { bottom: "ref_d1c"              top: "ref_d1c"   name: "ref_relu_d1c"       type: "ReLU" }

# conv layer with stride two instead of pooling
layer { bottom: "ref_d1c"               top: "ref_d1pool"   name:"ref_d1pool"             type:"Convolution" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 128 pad: 1 kernel_size: 3 stride: 2 weight_filler { type: "msra" } bias_filler { type: "constant" } }}
layer { bottom: "ref_d1pool"            top: "ref_d1pool"   name: "ref_relu_d1pool"       type: "ReLU" }

# float image
# encoder one
layer { bottom: "fl"                  top: "fl_d0b"   name: "fl_conv_d0a-b"     type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 64 pad: 1 kernel_size: 3 weight_filler { type: "msra" } bias_filler { type: "constant" } } }
layer { bottom: "fl_d0b"              top: "fl_d0b"   name: "fl_relu_d0b"       type: "ReLU" }
layer { bottom: "fl_d0b"              top: "fl_d0c"   name: "fl_conv_d0b-c"     type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 64 pad: 1 kernel_size: 3 weight_filler { type: "msra" } bias_filler { type: "constant" } } }
layer { bottom: "fl_d0c"              top: "fl_d0c"   name: "fl_relu_d0c"       type: "ReLU" }

# conv layer with stride two instead of pooling
layer { bottom: "fl_d0c"               top: "fl_d0pool"   name:"fl_d0pool"             type:"Convolution" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 64 pad: 1 kernel_size: 3 stride: 2 weight_filler { type: "msra" } bias_filler { type: "constant" } }}
layer { bottom: "fl_d0pool"            top: "fl_d0pool"   name: "fl_relu_d0pool"       type: "ReLU" }

## encoder two

layer { bottom: "fl_d0pool"           top: "fl_d1b"   name: "fl_conv_d1a-b"     type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 128 pad: 1 kernel_size: 3 weight_filler { type: "msra" } bias_filler { type: "constant" } } }
layer { bottom: "fl_d1b"              top: "fl_d1b"   name: "fl_relu_d1b"       type: "ReLU" }
layer { bottom: "fl_d1b"              top: "fl_d1c"   name: "fl_conv_d1b-c"     type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 128 pad: 1 kernel_size: 3 weight_filler { type: "msra" } bias_filler { type: "constant" } } }
layer { bottom: "fl_d1c"              top: "fl_d1c"   name: "fl_relu_d1c"       type: "ReLU" }

# conv layer with stride two instead of pooling
layer { bottom: "fl_d1c"               top: "fl_d1pool"   name:"fl_d1pool"             type:"Convolution" param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 128 pad: 1 kernel_size: 3 stride: 2 weight_filler { type: "msra" } bias_filler { type: "constant" } }}
layer { bottom: "fl_d1pool"            top: "fl_d1pool"   name: "fl_relu_d1pool"       type: "ReLU" }

## concatenation

layer { bottom: "ref_d1pool"        bottom: "fl_d1pool"   top: "concat"          name: "concat"     type: "Concat"  concat_param { axis: 1 }}

## decoding
# decoder one
layer { bottom: "concat"              top: "dec_d0b"  name: "dec_d0b"           type: "Deconvolution"   param { lr_mult: 0 }  convolution_param { num_output: 128 bias_term: false  kernel_size: 4  stride: 2 weight_filler: { type: "bilinear" }}}
layer { bottom: "dec_d0b"             top: "dec_d0b"  name: "dec_relu_d0b"      type: "ReLU" }
layer { bottom: "dec_d0b"             top: "dec_d0c"  name: "dec_conv_d0c"      type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 128 pad: 1 kernel_size: 3 weight_filler { type: "msra" } bias_filler { type: "constant" } } }
layer { bottom: "dec_d0c"             top: "dec_d0c"  name: "dec_relu_d0c"      type: "ReLU" }

# decoder two
layer { bottom: "dec_d0c"             top: "dec_d1b"  name: "dec_d1b"           type: "Deconvolution"   param { lr_mult: 0 }  convolution_param { num_output: 64 bias_term: false  kernel_size: 4  stride: 2 weight_filler: { type: "bilinear" }}}
layer { bottom: "dec_d1b"             top: "dec_d1b"  name: "dec_relu_d1b"      type: "ReLU" }
layer { bottom: "dec_d1b"             top: "dec_d1c"  name: "dec_conv_d1c"      type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 64 pad: 1 kernel_size: 3 weight_filler { type: "msra" } bias_filler { type: "constant" } } }
layer { bottom: "dec_d1c"             top: "dec_d1c"  name: "dec_relu_d1c"      type: "ReLU" }

layer { bottom: "dec_d1c"             top: "dec_d2b"  name: "dec_d2b"           type: "Convolution"  param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 2 pad: 1 kernel_size: 1 weight_filler { type: "msra" } bias_filler { type: "constant" } } }

## crop and loss layer
layer { bottom: "dec_d2b" bottom: "ref"  top: "crop" name: "crop"              type: "Crop"               crop_param { offset: 2 }}
  # crop_param {
  #   axis: 2
  #   offset: 19
  # }

layer { bottom: "crop"                   top: "loss"   name: "loss"              type: "Softmax"   softmax_param {engine: CAFFE}}
  # loss_param {
  #   ignore_label: 255
  #   normalize: false
  # }

# layer { bottom: "crop"                  top: "estimate" name: "estimate"        type: "Softmax"           softmax_param { engine: CAFFE axis: 2}}

layer {
    type: 'Python'
    name: 'testInference'
    bottom: 'fl'
    bottom: 'loss'
    bottom: 'label'
    python_param {
      module: "testInference"
      layer: "TestInference"
    }
    include {
      phase : TEST
    }
}